### **常见问题解答：Agentic 设计模式**

**什么是"agentic 设计模式"？** Agentic 设计模式是一种可重用的高级解决方案，用于解决构建智能自主系统（Agent）时遇到的常见问题。这些模式为设计 Agent 行为提供了结构化框架，就像软件设计模式为传统编程所做的那样。它们帮助开发人员构建更强大、更可预测和更有效的 AI Agent。

**本指南的主要目标是什么？** 本指南旨在提供设计和构建 agentic 系统的实用、实践性介绍。它超越了理论讨论，提供了开发人员可以使用的具体架构蓝图，以可靠的方式创建能够执行复杂、面向目标行为的 Agent。

**本指南的目标受众是谁？** 本指南面向正在使用大语言模型（LLM）和其他 AI 组件构建应用程序的 AI 开发人员、软件工程师和系统架构师。它适合那些希望从简单的提示-响应交互转向创建复杂自主 Agent 的人。

**4. 讨论了哪些关键的 agentic 模式？** 根据目录，本指南涵盖了几个关键模式，包括：

* **反思（Reflection）**：Agent 批评自己的行为和输出以提高性能的能力。
* **规划（Planning）**：将复杂目标分解为更小的、可管理的步骤或任务的过程。
* **工具使用（Tool Use）**：Agent 利用外部工具（如代码解释器、搜索引擎或其他 API）来获取信息或执行自己无法完成的操作的模式。
* **多 Agent 协作（Multi-Agent Collaboration）**：让多个专业 Agent 协同工作以解决问题的架构，通常涉及"领导者"或"编排者"Agent。
* **人在回路中（Human-in-the-Loop）**：整合人类监督和干预，允许对 Agent 的行为进行反馈、纠正和批准。

**为什么"规划"是一个重要的模式？** 规划至关重要，因为它允许 Agent 处理无法通过单个操作解决的复杂多步骤任务。通过创建计划，Agent 可以维护连贯的策略，跟踪其进度，并以结构化的方式处理错误或意外障碍。这可以防止 Agent"卡住"或偏离用户的最终目标。

**对于 Agent 来说，"工具"和"技能"之间有什么区别？** 虽然这些术语经常互换使用，但"工具"通常指 Agent 可以调用的外部资源（例如天气 API、计算器）。"技能"是 Agent 已学会的更集成的能力，通常将工具使用与内部推理相结合以执行特定功能（例如，"预订航班"的技能可能涉及使用日历和航空公司 API）。

**"反思"模式如何提高 Agent 的性能？** 反思充当自我纠正的形式。在生成响应或完成任务后，Agent 可以被提示审查其工作，检查错误，根据某些标准评估其质量，或考虑替代方法。这种迭代改进过程有助于 Agent 产生更准确、相关和高质量的结果。

**反思模式的核心思想是什么？** 反思模式使 Agent 能够退后一步并批评自己的工作。Agent 不是一次性产生最终输出，而是生成草稿，然后对其进行"反思"，识别缺陷、缺失信息或需要改进的地方。这个自我纠正过程是提高响应质量和准确性的关键。

**为什么简单的"提示链"不足以产生高质量的输出？** 简单的提示链（其中一个提示的输出成为下一个提示的输入）通常过于基础。模型可能只是重新措辞其先前的输出，而没有真正改进它。真正的反思模式需要更结构化的批评，提示 Agent 根据特定标准分析其工作，检查逻辑错误或验证事实。

**本章提到的两种主要反思类型是什么？** 本章讨论了两种主要的反思形式：

* **"检查你的工作"反思**：这是一种基本形式，Agent 只是被要求审查和修复其先前的输出。这是捕获简单错误的良好起点。
* **"内部批评者"反思**：这是一种更高级的形式，其中使用单独的"批评者"Agent（或专用提示）来评估"工作者"Agent 的输出。可以给这个批评者特定的标准来寻找，从而导致更严格和有针对性的改进。

**反思如何帮助减少"幻觉"？** 通过提示 Agent 审查其工作，特别是通过将其陈述与已知来源进行比较或检查其自己的推理步骤，反思模式可以显著降低幻觉（编造事实）的可能性。Agent 被迫更加基于提供的上下文，并且不太可能生成不受支持的信息。

**反思模式可以应用多次吗？** 可以，反思可以是一个迭代过程。可以让 Agent 多次反思其工作，每个循环进一步改进输出。这对于复杂任务特别有用，其中第一次或第二次尝试可能仍然包含细微错误或可以大幅改进。

**在 AI Agent 的背景下，规划模式是什么？** 规划模式涉及使 Agent 能够将复杂的高级目标分解为一系列较小的、可操作的步骤。Agent 不是试图一次性解决大问题，而是首先创建一个"计划"，然后执行计划中的每个步骤，这是一种更可靠的方法。

**为什么规划对复杂任务是必要的？** LLM 可能难以处理需要多个步骤或依赖关系的任务。如果没有计划，Agent 可能会失去对整体目标的跟踪，错过关键步骤，或者无法将一个步骤的输出作为下一个步骤的输入。计划提供了清晰的路线图，确保按逻辑顺序满足原始请求的所有要求。

**实现规划模式的常见方法是什么？** 一种常见的实现是让 Agent 首先以结构化格式（如 JSON 数组或编号列表）生成步骤列表。然后系统可以遍历此列表，逐一执行每个步骤，并将结果反馈给 Agent 以通知下一个操作。

**Agent 如何处理执行过程中的错误或变化？** 强大的规划模式允许动态调整。如果步骤失败或情况发生变化，可以提示 Agent 从当前状态"重新规划"。它可以分析错误，修改剩余步骤，或者甚至添加新步骤来克服障碍。

**用户会看到计划吗？** 这是一个设计选择。在许多情况下，首先向用户展示计划以供批准是一个很好的做法。这与"人在回路中"模式保持一致，在执行之前为用户提供对 Agent 提议行动的透明度和控制。

**"工具使用"模式需要什么？** 工具使用模式允许 Agent 通过与外部软件或 API 交互来扩展其能力。由于 LLM 的知识是静态的，并且它无法自行执行真实世界的操作，工具使它能够访问实时信息（例如 Google 搜索）、专有数据（例如公司数据库）或执行操作的能力（例如发送电子邮件、预订会议）。

**Agent 如何决定使用哪个工具？** Agent 通常会获得可用工具列表以及每个工具的功能描述和所需参数。当面对无法用内部知识处理的请求时，Agent 的推理能力允许它从列表中选择最合适的工具来完成任务。

**在此背景下提到的"ReAct"（推理与行动）框架是什么？** ReAct 是一个流行的框架，集成了推理和行动。Agent 遵循**思考**（推理它需要做什么）、**行动**（决定使用哪个工具以及使用什么输入）和**观察**（查看工具的结果）的循环。此循环继续，直到它收集了足够的信息来满足用户的请求。

**实现工具使用的一些挑战是什么？** 主要挑战包括：

* **错误处理**：工具可能失败、返回意外数据或超时。Agent 需要能够识别这些错误并决定是否重试、使用不同的工具或寻求用户帮助。
* **安全性**：让 Agent 访问工具，特别是那些执行操作的工具，具有安全隐患。对于敏感操作，拥有保障措施、权限以及通常需要人工批准至关重要。
* **提示**：必须有效地提示 Agent 以生成格式正确的工具调用（例如，正确的函数名称和参数）。

**什么是人在回路中（HITL）模式？** HITL 是一种将人类监督和交互整合到 Agent 工作流程中的模式。Agent 不是完全自主的，而是在关键节点暂停以寻求人类反馈、批准、澄清或指导。

**为什么 HITL 对 agentic 系统很重要？** 它至关重要有几个原因：

* **安全和控制**：对于高风险任务（例如金融交易、发送正式通信），HITL 确保人类在执行之前验证 Agent 提议的行动。
* **提高质量**：人类可以提供纠正或细微的反馈，Agent 可以使用这些反馈来提高其性能，特别是在主观或模糊的任务中。
* **建立信任**：用户更有可能信任和采用他们可以指导和监督的 AI 系统。

**在工作流程中的哪些点应该包括人类？** 人类干预的常见点包括：

* **计划批准**：在执行多步骤计划之前。
* **工具使用确认**：在使用具有现实世界后果或花费金钱的工具之前。
* **消除歧义**：当 Agent 不确定如何继续或需要用户提供更多信息时。
* **最终输出审查**：在向最终用户或系统交付最终结果之前。

**持续的人类干预不是效率低下吗？** 可能是，这就是为什么关键是找到正确的平衡。HITL 应该在关键检查点实施，而不是每个操作都需要。目标是在人类和 Agent 之间建立协作伙伴关系，其中 Agent 处理大部分工作，人类提供战略指导。

**什么是多 Agent 协作模式？** 此模式涉及创建由多个专业 Agent 组成的系统，它们协同工作以实现共同目标。您不是创建一个试图做所有事情的"通才"Agent，而是创建一个"专家"Agent 团队，每个都有特定的角色或专业知识。

**多 Agent 系统的好处是什么？**

* **模块化和专业化**：每个 Agent 都可以针对其特定任务进行微调和提示（例如"研究员"Agent、"写作"Agent、"代码"Agent），从而获得更高质量的结果。
* **降低复杂性**：将复杂的工作流程分解为专业角色使整个系统更易于设计、调试和维护。
* **模拟头脑风暴**：不同的 Agent 可以对问题提供不同的观点，从而产生更有创意和更强大的解决方案，类似于人类团队的工作方式。

**多 Agent 系统的常见架构是什么？** 一个常见的架构涉及一个**编排者 Agent**（有时称为"管理者"或"指挥者"）。编排者理解整体目标，将其分解，并将子任务委派给适当的专家 Agent。然后它从专家那里收集结果并将它们综合成最终输出。

**Agent 之间如何相互通信？** 通信通常由编排者管理。例如，编排者可能将"研究员"Agent 的输出作为上下文传递给"写作"Agent。Agent 可以发布其发现的共享"草稿本"或消息总线是另一种常见的通信方法。

**为什么评估 Agent 比评估传统软件程序更困难？** 传统软件具有确定性输出（相同的输入总是产生相同的输出）。Agent，特别是使用 LLM 的 Agent，是非确定性的，它们的性能可能是主观的。评估它们需要评估输出的*质量*和*相关性*，而不仅仅是它是否在技术上"正确"。

**评估 Agent 性能的一些常见方法是什么？** 本指南建议了几种方法：

* **基于结果的评估**：Agent 是否成功实现了最终目标？例如，如果任务是"预订航班"，是否真的正确预订了航班？这是最重要的衡量标准。
* **基于过程的评估**：Agent 的*过程*是否高效且合乎逻辑？它是否使用了正确的工具？它是否遵循了合理的计划？这有助于调试为什么 Agent 可能失败。
* **人工评估**：让人类根据有用性、准确性和连贯性等标准在量表上（例如 1-5）对 Agent 的性能进行评分。这对于面向用户的应用程序至关重要。

**什么是"Agent 轨迹"？** Agent 轨迹是 Agent 在执行任务时的完整步骤日志。它包括其所有思考、操作（工具调用）和观察。分析这些轨迹是调试和理解 Agent 行为的关键部分。

**如何为非确定性系统创建可靠的测试？** 虽然您无法保证 Agent 输出的确切措辞，但您可以创建检查关键元素的测试。例如，您可以编写一个测试来验证 Agent 的最终响应是否*包含*特定信息，或者它是否成功使用正确的参数调用了某个工具。这通常在专用测试环境中使用模拟工具完成。

**提示 Agent 与简单的 ChatGPT 提示有何不同？** 提示 Agent 涉及创建详细的"系统提示"或章程，作为其操作指令。这超越了单个用户查询；它定义了 Agent 的角色、可用工具、应遵循的模式（如 ReAct 或规划）、约束和个性。

**Agent 良好系统提示的关键组成部分是什么？** 强大的系统提示通常包括：

* **角色和目标**：明确定义 Agent 是谁以及其主要目的是什么。
* **工具定义**：可用工具列表、它们的描述以及如何使用它们（例如，以特定的函数调用格式）。
* **约束和规则**：关于 Agent *不应该*做什么的明确指令（例如，"未经批准不要使用工具"，"不要提供财务建议"）。
* **过程指令**：关于使用哪些模式的指导。例如，"首先，创建一个计划。然后，逐步执行计划。"
* **示例轨迹**：提供几个成功的"思考-行动-观察"循环的示例可以显著提高 Agent 的可靠性。

**什么是"提示泄漏"？** 提示泄漏发生在系统提示的部分（如工具定义或内部指令）在 Agent 向用户的最终响应中无意中被揭示时。这可能会让用户感到困惑并暴露底层实现细节。使用单独的提示进行推理和生成最终答案等技术可以帮助防止这种情况。

**agentic 系统的一些未来趋势是什么？** 本指南指出了未来的发展方向：

* **更自主的 Agent**：需要更少人类干预并且可以自己学习和适应的 Agent。
* **高度专业化的 Agent**：可以为特定任务雇用或订阅的 Agent 生态系统（例如旅行 Agent、研究 Agent）。
* **更好的工具和平台**：开发更复杂的框架和平台，使构建、测试和部署强大的多 Agent 系统变得更容易。