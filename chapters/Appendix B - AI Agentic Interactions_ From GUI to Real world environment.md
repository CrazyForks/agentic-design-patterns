# 附录 B - AI Agentic 交互：从 GUI 到现实世界环境

AI Agent 越来越多地通过与数字界面和物理世界的交互来执行复杂任务。它们在这些不同环境中感知、处理和行动的能力正在从根本上改变自动化、人机交互和智能系统。本附录探讨了 Agent 如何与计算机及其环境交互，重点介绍了相关进展和项目。

## 交互：Agent 与计算机

AI 从对话伙伴到主动的、面向任务的 Agent 的演变是由 Agent-计算机界面（ACI）驱动的。这些界面允许 AI 直接与计算机的图形用户界面（GUI）交互，使其能够像人类一样感知和操作图标和按钮等视觉元素。这种新方法超越了依赖 API 和系统调用的传统自动化的刚性、依赖开发人员的脚本。通过使用软件的视觉"前门"，AI 现在可以以更灵活和强大的方式自动化复杂的数字任务，这个过程涉及几个关键阶段：

* **视觉感知**：Agent 首先捕获屏幕的视觉表示，本质上是截屏。
* **GUI 元素识别**：然后它分析此图像以区分各种 GUI 元素。它必须学会将屏幕"看作"不仅仅是像素的集合，而是具有交互组件的结构化布局，区分可点击的"提交"按钮与静态横幅图像或可编辑文本字段与简单标签。
* **上下文解释**：ACI 模块充当视觉数据与 Agent 核心智能（通常是大型语言模型或 LLM）之间的桥梁，在任务上下文中解释这些元素。它理解放大镜图标通常意味着"搜索"，或者一系列单选按钮代表选择。这个模块对于增强 LLM 的推理至关重要，允许它基于视觉证据形成计划。
* **动态行动和响应**：然后 Agent 通过程序控制鼠标和键盘来执行其计划——点击、打字、滚动和拖动。至关重要的是，它必须持续监控屏幕以获取视觉反馈，动态响应变化、加载屏幕、弹出通知或错误，以成功导航多步骤工作流。

这项技术不再是理论上的。几个领先的 AI 实验室已经开发出功能性 Agent，展示了 GUI 交互的强大能力：

**ChatGPT Operator（OpenAI）**：作为数字合作伙伴的愿景，ChatGPT Operator 旨在直接从桌面自动化跨广泛应用的任务。它理解屏幕元素，使其能够执行诸如将数据从电子表格传输到客户关系管理（CRM）平台、在航空公司和酒店网站上预订复杂的旅行行程，或填写详细的在线表单等操作，而无需为每个服务提供专门的 API 访问。这使它成为一个普遍适用的工具，旨在通过接管重复的数字工作来提高个人和企业的生产力。

**Google Project Mariner**：作为研究原型，Project Mariner 作为 Chrome 浏览器内的 Agent 运行（见图 1）。其目的是理解用户的意图并代表他们自主执行基于网络的任务。例如，用户可以要求它在特定预算和社区内找到三套出租公寓；Mariner 然后会导航到房地产网站，应用过滤器，浏览列表，并将相关信息提取到文档中。这个项目代表了 Google 在创建一个真正有用且"代理性"的网络体验方面的探索，其中浏览器主动为用户工作。

![][image1]

图 1：Agent 与网络浏览器之间的交互

**Anthropic 的计算机使用**：此功能使 Anthropic 的 AI 模型 Claude 成为计算机桌面环境的直接用户。通过捕获屏幕截图来感知屏幕并以程序方式控制鼠标和键盘，Claude 可以编排跨多个不相连应用的工作流。用户可以要求它分析 PDF 报告中的数据，打开电子表格应用程序对该数据进行计算，生成图表，然后将该图表粘贴到电子邮件草稿中——这是一系列以前需要持续人工输入的任务。

**Browser Use**：这是一个开源库，提供用于程序化浏览器自动化的高级 API。它使 AI Agent 能够通过授予它们访问和控制文档对象模型（DOM）的权限来与网页交互。该 API 将浏览器控制协议的复杂、低级命令抽象为一组更简化和直观的函数。这允许 Agent 执行复杂的操作序列，包括从嵌套元素中提取数据、表单提交以及跨多个页面的自动导航。因此，该库促进了将非结构化网络数据转换为 AI Agent 可以系统地处理和利用以进行分析或决策的结构化格式。

## 交互：Agent 与环境

超越计算机屏幕的限制，AI Agent 越来越多地被设计为与复杂、动态的环境交互，通常反映现实世界。这需要复杂的感知、推理和执行能力。

Google 的 **Project Astra** 是一个推动 Agent 与环境交互界限的举措的主要例子。Astra 旨在创建一个在日常生活中有用的通用 AI Agent，利用多模态输入（视觉、声音、语音）和输出来理解并与世界进行上下文交互。这个项目专注于快速理解、推理和响应，允许 Agent 通过摄像头和麦克风"看到"和"听到"其周围环境，并在提供实时帮助的同时进行自然对话。Astra 的愿景是一个可以无缝协助用户完成从寻找丢失物品到调试代码等任务的 Agent，通过理解它观察到的环境。这超越了简单的语音命令，实现了对用户直接物理上下文的真正具体理解。

Google 的 **Gemini Live** 将标准 AI 交互转变为流畅和动态的对话。用户可以与 AI 交谈并以最小延迟接收自然发音的响应，甚至可以中断或在句子中间更改话题，促使 AI 立即适应。界面扩展到语音之外，允许用户通过使用手机摄像头、共享屏幕或上传文件来整合视觉信息，以进行更具上下文意识的讨论。更高级的版本甚至可以感知用户的语气并智能地过滤掉不相关的背景噪音，以更好地理解对话。这些能力结合起来创造了丰富的交互，例如通过简单地将摄像头指向它来接收任务的实时指导。

OpenAI 的 **GPT-4o 模型**是一个为"全方位"交互设计的替代方案，这意味着它可以跨语音、视觉和文本进行推理。它以反映人类响应时间的低延迟处理这些输入，从而允许实时对话。例如，用户可以向 AI 展示实时视频源以询问正在发生什么的问题，或将其用于语言翻译。OpenAI 为开发人员提供了"实时 API"，用于构建需要低延迟、语音到语音交互的应用。

OpenAI 的 **ChatGPT Agent** 代表了对其前身的重大架构进步，具有新功能的集成框架。其设计包含几个关键功能模式：自主导航实时互联网以进行实时数据提取的能力、动态生成和执行计算代码以完成数据分析等任务的能力，以及直接与第三方软件应用程序交互的功能。这些功能的综合允许 Agent 从单一用户指令编排和完成复杂的、顺序的工作流。因此，它可以自主管理整个流程，例如执行市场分析并生成相应的演示文稿，或规划物流安排并执行必要的交易。在发布的同时，OpenAI 主动解决了此类系统固有的新兴安全考虑。附带的"系统卡"描述了与能够在线执行操作的 AI 相关的潜在操作危害，承认了滥用的新途径。为了减轻这些风险，Agent 的架构包括工程化的保障措施，例如要求某些类别的操作获得明确的用户授权，并部署强大的内容过滤机制。该公司现在正在让其初始用户群通过反馈驱动的迭代过程进一步完善这些安全协议。

**Seeing AI** 是 Microsoft 的一款免费移动应用，通过提供周围环境的实时叙述，为盲人或低视力人士赋能。该应用通过设备的摄像头利用人工智能来识别和描述各种元素，包括物体、文本甚至人物。其核心功能包括阅读文档、识别货币、通过条形码识别产品以及描述场景和颜色。通过提供对视觉信息的增强访问，Seeing AI 最终促进了视觉障碍用户的更大独立性。

**Anthropic 的 Claude 4 系列** Anthropic 的 Claude 4 是另一个具有高级推理和分析能力的替代方案。虽然历史上专注于文本，但 Claude 4 包括强大的视觉能力，允许它处理来自图像、图表和文档的信息。该模型适合处理复杂的多步骤任务并提供详细的分析。虽然实时对话方面不是其主要关注点（与其他模型相比），但其底层智能旨在构建高度能干的 AI Agent。

## Vibe 编码：使用 AI 的直观开发

除了与 GUI 和物理世界的直接交互之外，开发人员使用 AI 构建软件的方式正在出现一种新的范式："vibe 编码"。这种方法摆脱了精确的、逐步的指令，而是依赖于开发人员与 AI 编码助手之间更直观、对话式和迭代的交互。开发人员提供高级目标、期望的"氛围"或一般方向，AI 生成代码以匹配。

这个过程的特点是：

- **对话式提示**：开发人员可能会说"为新应用创建一个简单、现代外观的登录页面"，或"重构此函数使其更具 Pythonic 风格和可读性"，而不是编写详细的规范。AI 解释"现代"或"Pythonic"的"氛围"并生成相应的代码。
- **迭代改进**：AI 的初始输出通常是起点。然后开发人员以自然语言提供反馈，例如"这是一个好的开始，但你能把按钮做成蓝色吗？"或"给那个添加一些错误处理。"这种来回继续，直到代码满足开发人员的期望。
- **创意合作伙伴关系**：在 vibe 编码中，AI 充当创意合作伙伴，提出开发人员可能没有考虑过的想法和解决方案。这可以加速开发过程并导致更具创新性的结果。
- **关注"什么"而不是"如何"**：开发人员专注于期望的结果（"什么"），并将实施细节（"如何"）留给 AI。这允许快速原型设计和探索不同的方法，而不会陷入样板代码。
- **可选的内存库**：为了在较长的交互中保持上下文，开发人员可以使用"内存库"来存储关键信息、偏好或约束。例如，开发人员可能会将特定的编码风格或一组项目要求保存到 AI 的内存中，确保未来的代码生成与已建立的"氛围"保持一致，而无需重复指令。

随着像 GPT-4、Claude 和 Gemini 这样的强大 AI 模型集成到开发环境中，Vibe 编码变得越来越流行。这些工具不仅仅是自动完成代码；它们正在积极参与软件开发的创意过程，使其更易于访问和高效。这种新的工作方式正在改变软件工程的本质，强调创造力和高级思维，而不是死记硬背语法和 API。

## 关键要点

* AI Agent 正在从简单的自动化演变为通过图形用户界面在视觉上控制软件，就像人类一样。
* 下一个前沿是与现实世界的交互，像 Google 的 Astra 这样的项目使用摄像头和麦克风来观察、听到和理解其物理环境。
* 领先的技术公司正在汇聚这些数字和物理能力，以创建跨两个领域无缝运行的通用 AI 助手。
* 这种转变正在创造一类新的主动的、具有上下文意识的 AI 伙伴，能够协助用户日常生活中的大量任务。

## 结论

Agent 正在经历重大转变，从基本自动化转向与数字和物理环境的复杂交互。通过利用视觉感知来操作图形用户界面，这些 Agent 现在可以像人类一样操作软件，绕过对传统 API 的需求。主要技术实验室正在开创这一领域，其 Agent 能够直接在用户桌面上自动化复杂的多应用工作流。同时，下一个前沿正在扩展到物理世界，像 Google 的 Project Astra 这样的举措使用摄像头和麦克风在上下文中与周围环境互动。这些高级系统旨在实现反映人类交互的多模态、实时理解。

最终愿景是汇聚这些数字和物理能力，创建跨用户所有环境无缝运行的通用 AI 助手。这种演变也通过"vibe 编码"重塑了软件创建本身，这是开发人员与 AI 之间更直观和对话式的合作伙伴关系。这种新方法优先考虑高级目标和创意意图，允许开发人员专注于期望的结果而不是实施细节。这种转变通过将 AI 视为创意合作伙伴来加速开发并促进创新。最终，这些进步正在为主动的、具有上下文意识的 AI 伙伴的新时代铺平道路，能够协助我们日常生活中的大量任务。

## 参考文献

1. Open AI Operator, [https://openai.com/index/introducing-operator/](https://openai.com/index/introducing-operator/)   
2. Open AI ChatGPT Agent: [https://openai.com/index/introducing-chatgpt-agent/](https://openai.com/index/introducing-chatgpt-agent/)   
3. Browser Use: [https://docs.browser-use.com/introduction](https://docs.browser-use.com/introduction)   
4. Project Mariner, [https://deepmind.google/models/project-mariner/](https://deepmind.google/models/project-mariner/)   
5. Anthropic Computer use: [https://docs.anthropic.com/en/docs/build-with-claude/computer-use](https://docs.anthropic.com/en/docs/build-with-claude/computer-use)  
6. Project Astra, [https://deepmind.google/models/project-astra/](https://deepmind.google/models/project-astra/)   
7. Gemini Live, [https://gemini.google/overview/gemini-live/?hl=en](https://gemini.google/overview/gemini-live/?hl=en)   
8. OpenAI's GPT-4,  [https://openai.com/index/gpt-4-research/](https://openai.com/index/gpt-4-research/)   
9. Claude 4, [https://www.anthropic.com/news/claude-4](https://www.anthropic.com/news/claude-4) 

[image1]: ../images/appendix-b/image1.png